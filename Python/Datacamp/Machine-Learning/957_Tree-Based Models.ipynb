{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc = pd.read_csv('Datasets/wbc.csv')\n",
    "\n",
    "wbc = wbc.drop(['Unnamed: 32'], axis=1)\n",
    "\n",
    "X = wbc.loc[:, ['radius_mean', 'concave points_mean']].values\n",
    "y = wbc.iloc[:, 1]\n",
    "y = y.replace('M', 1)\n",
    "y = y.replace('B', 0)\n",
    "y = y.values\n",
    "\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Logistic regression vs classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "\n",
    "# Instatiate logreg\n",
    "logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit logreg to the training set\n",
    "logreg.fit(X_test, y_test)\n",
    "\n",
    "# Define a list called clfs containing the two classifiers logreg and dt\n",
    "clfs = [logreg, dt]\n",
    "\n",
    "# Review the decision regions of the two classifiers\n",
    "plot_labeled_decision_regions(X_test, y_test, clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Datasets/images/logreg_vs_treeClassification.svg\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice how the decision boundary produced by logistic regression is linear while the boundaries produced by the classification tree divide the feature space into rectangular regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Entropy vs Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.8859649122807017\n",
      "Accuracy achieved by using the gini index:  0.8859649122807017\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "\n",
    "for i, type_criterion in enumerate(['entropy', 'gini index']):\n",
    "\n",
    "    # Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "    dt = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
    "\n",
    "    # Fit dt_entropy to the training set\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # Use dt_entropy to predict test set labels\n",
    "    y_pred= dt.predict(X_test)\n",
    "\n",
    "    # Evaluate accuracy_entropy\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('Accuracy achieved by using entropy: ', accuracy[0])\n",
    "\n",
    "# Print accuracy_gini\n",
    "print('Accuracy achieved by using the gini index: ', accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Notice how the two models achieve exactly the same accuracy. Most of the time, the gini index and entropy lead to the same results. The gini index is slightly faster to compute and is the default criterion used in the DecisionTreeClassifier model of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('Datasets/auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>US</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>Europe</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  origin  size\n",
       "0  18.0  250.0   88    3139   14.5      US  15.0\n",
       "1   9.0  304.0  193    4732   18.5      US  20.0\n",
       "2  36.1   91.0   60    1800   16.4    Asia  10.0\n",
       "3  18.5  250.0   98    3525   19.0      US  15.0\n",
       "4  34.3   97.0   78    2188   15.8  Europe  10.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>size</th>\n",
       "      <th>origin_Europe</th>\n",
       "      <th>origin_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ  hp  weight  accel  size  origin_Europe  origin_US\n",
       "0  18.0  250.0  88    3139   14.5  15.0              0          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.get_dummies(auto, drop_first=True)\n",
    "auto.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = auto.mpg.values\n",
    "X = auto.drop([\"mpg\"], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=4,\n",
    "             min_samples_leaf=0.26,\n",
    "            random_state=3)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 4.86\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute y_pred\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute mse_dt\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute rmse_dt\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "\n",
    "# Print rmse_dt\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  n_jobs=-1) \n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Ensemble Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "y = data.target\n",
    "X = data.data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNeighborsClassifier(n_neighbors=27)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.924\n",
      "K Nearest Neighbours : 0.912\n",
      "Classification Tree : 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/becode/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    "  \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "  \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "  \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/becode/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc \n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0  1.247403            -0.420320             -0.495414   \n",
       "1  1.062306             1.218936              1.423518   \n",
       "2  1.062306             0.640375              0.926017   \n",
       "3  0.815511            -0.372106             -0.388807   \n",
       "4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients = pd.read_csv('Datasets/indian_liver_patient/indian_liver_patient_preprocessed.csv', index_col=0)\n",
    "patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = patients.Liver_disease.values\n",
    "X = patients.drop(['Liver_disease'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Fit bc to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Import BaggingClassifier \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, oob_score=True, random_state=1)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A single tree dt would have achieved an accuracy of 64% which is 8% lower than bc's accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB Score vs Test Set Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.716, OOB accuracy: 0.708\n"
     ]
    }
   ],
   "source": [
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>instant</th>\n",
       "      <th>mnth</th>\n",
       "      <th>yr</th>\n",
       "      <th>Clear to partly cloudy</th>\n",
       "      <th>Light Precipitation</th>\n",
       "      <th>Misty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>13004</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>93</td>\n",
       "      <td>13005</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>90</td>\n",
       "      <td>13006</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>33</td>\n",
       "      <td>13007</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4</td>\n",
       "      <td>13008</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hr  holiday  workingday  temp   hum  windspeed  cnt  instant  mnth  yr  \\\n",
       "0   0        0           0  0.76  0.66     0.0000  149    13004     7   1   \n",
       "1   1        0           0  0.74  0.70     0.1343   93    13005     7   1   \n",
       "2   2        0           0  0.72  0.74     0.0896   90    13006     7   1   \n",
       "3   3        0           0  0.72  0.84     0.1343   33    13007     7   1   \n",
       "4   4        0           0  0.70  0.79     0.1940    4    13008     7   1   \n",
       "\n",
       "   Clear to partly cloudy  Light Precipitation  Misty  \n",
       "0                       1                    0      0  \n",
       "1                       1                    0      0  \n",
       "2                       1                    0      0  \n",
       "3                       1                    0      0  \n",
       "4                       1                    0      0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike = pd.read_csv('Datasets/bikes.csv')\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    744\n",
       "7    744\n",
       "Name: mnth, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.mnth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bike.cnt.values\n",
    "X = bike.drop(['cnt'], axis=1).values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=25, random_state=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "                           random_state=2)\n",
    "                           \n",
    "# Fit rf to the training set            \n",
    "rf.fit(X_train, y_train)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 51.84\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 128.34\n"
     ]
    }
   ],
   "source": [
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The test set RMSE achieved by rf is significantly smaller than that achieved by a single CART!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= bike.drop(['cnt'], axis=1).columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hr and workingday are the most important features according to rf. The importances of these two features add up to more than 90%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0  1.247403            -0.420320             -0.495414   \n",
       "1  1.062306             1.218936              1.423518   \n",
       "2  1.062306             0.640375              0.926017   \n",
       "3  0.815511            -0.372106             -0.388807   \n",
       "4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients = pd.read_csv('Datasets/indian_liver_patient/indian_liver_patient_preprocessed.csv', index_col=0)\n",
    "patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = patients.Liver_disease.values\n",
    "X = patients.drop(['Liver_disease'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This untuned AdaBoost classifier achieved a ROC AUC score of 0.64!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = auto.mpg.values\n",
    "X = auto.drop([\"mpg\"], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(max_depth=4,\n",
    "                               n_estimators=200,\n",
    "                               random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 4.194\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = mse_test**(1/2)\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Stochastic Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "                                 subsample=0.9,\n",
    "                                 max_features=0.75,\n",
    "                                 n_estimators=200,                                \n",
    "                                 random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit sgbr to the training set\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = sgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of sgbr: 4.194\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute test set MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute test set RMSE\n",
    "rmse_test = mse_test**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) GridSearchCV in Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = patients.Liver_disease.values\n",
    "X = patients.drop(['Liver_disease'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Define params_dt\n",
    "params_dt = {\n",
    "             'max_depth': [2, 3, 4],\n",
    "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it to the data\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=3, min_samples_leaf=0.14)\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearchcv score is better only decision tree classifier (dt), only dt was 0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) GridSearchCV in Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = auto.mpg.values\n",
    "X = auto.drop([\"mpg\"], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {\n",
    "             'n_estimators': [100, 350, 500],\n",
    "             'max_features': ['log2', 'auto', 'sqrt'],\n",
    "             'min_samples_leaf': [2, 10, 30], \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   21.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(min_samples_leaf=2)\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 3.945\n"
     ]
    }
   ],
   "source": [
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
